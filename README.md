# [데이콘] 소비자 데이터 기반 소비 예측 경진대회
## 개요
 두 번째로 참여한 대회로 Basic이라 데이터의 크기나 난이도가 높지 않아 초심자들에게 좋은 데이콘 대회인 것 같다.
데이터 크기는 1108 * 24 가 기본이라 예측대회용 자료론 매우 작아 원하는 조합의 하이퍼파라미터나 확인해보고 싶은 사실을
확인하는데 시간이 짧게 걸려 여러 방법들을 실험해볼 수 있었던 것 같다. 물론 실력이 부족해 등수가 좋게 나온 것은 아니었지만..
## EDA 및 전처리 
원래는 직접 그래프를 그려보고 feature-target 관련성이나 heatmap, countplot 같은 것들을 그려보면서 했으나
이번에 공유 코드에서 pandas_profiling이라는 좋은 라이브러리를 발견해 이용해봤다.
``` python
import pandas_profiling
train.profile_report()
```
미세하게 조정할 순 없지만 각 변수 별 분포나 상관관계 그래프, missing values와 중복 행까지 한번에 확인해주는 편리한 도구였다. 간단하게 overview 하고 싶을때 간간히 사용할 것 같다. 
데이터가 쇼핑몰 이용자 정보를 통해 소비를 얼마나 할지 예측하는 것이기에 소득이나 구매 횟수가 target과 연관성이 짙은 것으로 나왔다. 이와 관련된 파생변수로 '자녀 1인당 소득', '멤버십 기간', '나이', '총 구매횟수', 방문횟수 당 구매', '나이 그룹'을 생성하였고 범주형 변수는 라벨 인코딩을 해주었다.
데이터가 워낙 작아 이상치를 제거해주는 것이 오히려 성능을 떨어뜨려 나이가 100살 이상인 행 2개만 없애주었다. 

## 모델링
### Pycaret
전형적인 AutoML로 기본적인 값들만 지정해줘도 알아서 22개가 넘는 머신러닝 알고리즘들을 학습시켜주고 결과를 주루룩 보여주는 편한 패키지였다. 
이전에 한 번 사용해본적은 있으나 이것만 사용하기엔 내 실력 향상에 전혀 도움이 되지 않으므로 어떤 알고리즘들이 점수가 좋게 나오는지 확인하는 용도로만 사용하였다. 
간단히 돌려본 결과, ExtraTrees, RandomForest, XGBoost, GradientBoost, LightGBM, CatBoost 이 6개의 모델이 좋은 성능을 보였다. 
공유 코드에서도 단골로 보이는 모델들이라 반가웠다. 

### 개별 modeling
직접 여러 모델들 돌려보는 건 또 처음이라 하이퍼파라미터 튜닝하는 것도 애를 먹었다. 이런 정형 데이터에선 어떤 모델들이 효율적인지, 튜닝 값의 범위는 처음에 어떻게 선정하고 어떻게 좁혀나가는지, 이건 왜 성능이 갑자기 급락하는지, 제대로 성능 측정은 하고있는게 맞는지 등등 많은 궁금증과 난관들이 있었다. 결국엔, 
1) 기본적인 GridSearchCV 함수를 이용해 대충 범위를 잡고 돌려봤다. 가장 성능이 좋았던 ExtraTreesRegressor를 기준으로 열심히 돌려보고 처음 submission을 내봤는데 덜컥 리더보드에서 1등이 나오자 굉장히 당황했던 기억이 생생하다. 
2) 직접 지정하는 방식 말고 RandomizedsearchCV를 이용하여 구간으로 찾아보려 했으나 실패하였다.
3) optuna 패키지의 TPESampler라는 것을 찾아 이용하였다. Bayesian optimization 기법을 통해 최적의 파라미터 조합을 자동으로 탐색해주는 매우 좋은 패키지였다. 처음엔 optunasearchCV를 사용했으나 결국엔 study를 직접 지정하여 조합을 찾는 방식을 택했고 성능 역시 가장 좋게 나왔다!
 
 ### 앙상블
 사실 처음부터 리더보드 상으로 점수가 잘 나와(이것도 추후에 의미없다는걸 알았지만..) 굳이 앙상블을 해야하나 싶었지만 단일 모델 추론의 결과로는 불안정할 뿐더러 실제 점수도 올라갔기에 Softvoting 기법을 통해 4개 모델(ExtraTrees, XGBoost, GBoost, LightGBM)을 앙상블 한 결과를 제출하였다. 
 
 ## 결론
 1) 단순한 정형 target에 대한 예측이였지만 처음 여러 모델들을 다루고 비교해보았으며 tree기반의 알고리즘들이 돌아가는 형태를 대충 파악하게 되었다. 예를 들면, 데이터의 scale에 민감한 딥러닝 구조에 비해 트리 구조는 그리 민감하지 않는다던가, 직접 노가다를 뛰지 않고 TPESampler와 같은 방법을 이용한다던가 하는 점들이다.
 2) public score의 리더보드에 크게 연연해할 필요가 없었다. 오히려 public에 overfitting이 되어 private score가 제대로 나오지 않았다. 실제로 public은 4위였으나 private 순위는 11위로 많이 떨어졌었다. 
 3) EDA를 통해 데이터에서 인사이트를 얻는 실력을 더 기를 필요가 있다. 이번이야 데이터가 작고 잘 정제되어 있어서 큰 영향이 없었지만 데이터가 커지고 도메인 지식이 더 중요해지는 대회의 경우 나의 밑천이 여실히 드러날 것이다. 
 4) 데이터가 워낙 작아 거의 모든 과정에서 cross-validation을 사용하였으나 시간 관계상 다른 대회에선 힘들 것이다.(특히 딥러닝) 물론 크면 test셋을 적절히 떼어내서 사용해도 성능 측정엔 큰 무리가 없겠지만 최대한 대회 구성과 비슷하게 분리하는 방법을 찾아봐야겠다. 
  정말 간단한 대회였지만 처음 겪는 것들이 많아 시행착오가 꽤 있었다. 아무리 잘하는 사람이더라도 처음은 있는 법이니 관련 논문도 많이 읽고 실력을 차곡차곡 쌓아서 천천히 나아가보겠다!
